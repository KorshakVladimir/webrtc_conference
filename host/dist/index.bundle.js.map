{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///./node_modules/video-stream-merger/src/index.js","webpack:///./node_modules/clamp/index.js","webpack:///./node_modules/audio-frequency-to-index/index.js","webpack:///./node_modules/analyser-frequency-average/index.js","webpack:///./node_modules/voice-activity-detection/index.js","webpack:///./src/main.js"],"names":[],"mappings":";AAAA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA,yDAAiD,cAAc;AAC/D;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;;AAGA;AACA;;;;;;;ACnEA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,qDAAqD,YAAY;AACjE;;AAEA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,iBAAiB,0BAA0B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,0BAA0B;AAC3C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,uDAAuD,WAAW,SAAS,sBAAsB;AACjG;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,iBAAiB,0BAA0B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,uBAAuB,yBAAyB;AAChD;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;;AAEA;;;;;;;ACnUA;;AAEA;AACA;AACA;AACA;AACA;;;;;;;ACNA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACPA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,aAAa;AACrB;AACA;AACA;AACA;;;;;;;;AChBA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL,oFAAoF,wBAAwB;;AAE5G;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,UAAU;AACV,E;;;;;;;AC/HA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,+BAA+B,YAAY;AAC3C,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK,uCAAuC;AAC5C,QAAQ,gCAAgC;AACxC,QAAQ;AACR;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA,CAAC;;;;AAID;AACA;AACA;AACA;AACA;AACA,IAAI;;AAEJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA,CAAC;;AAED;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA,UAAU;AACV,SAAS;AACT,QAAQ;AACR;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,oBAAoB;AACpD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,EAAE;AACF;AACA,iC","file":"index.bundle.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 5);\n","/* globals window */\n\nmodule.exports = VideoStreamMerger\n\nfunction VideoStreamMerger (opts) {\n  var self = this\n  if (!(self instanceof VideoStreamMerger)) return new VideoStreamMerger(opts)\n\n  opts = opts || {}\n\n  var AudioContext = window.AudioContext || window.webkitAudioContext\n  var audioSupport = !!(AudioContext && (self._audioCtx = (opts.audioContext || new AudioContext())).createMediaStreamDestination)\n  var canvasSupport = !!document.createElement('canvas').captureStream\n  var supported = audioSupport && canvasSupport\n  if (!supported) {\n    throw new Error('Unsupported browser')\n  }\n  self.width = opts.width || 400\n  self.height = opts.height || 300\n  self.fps = opts.fps || 25\n  self.clearRect = opts.clearRect === undefined ? true : opts.clearRect\n\n  // Hidden canvas element for merging\n  self._canvas = document.createElement('canvas')\n  self._canvas.setAttribute('width', self.width)\n  self._canvas.setAttribute('height', self.height)\n  self._canvas.setAttribute('style', 'position:fixed; left: 110%; pointer-events: none') // Push off screen\n  self._ctx = self._canvas.getContext('2d')\n\n  self._streams = []\n\n  self._audioDestination = self._audioCtx.createMediaStreamDestination()\n\n  self._setupConstantNode() // HACK for wowza #7, #10\n\n  self.started = false\n  self.result = null\n\n  self._backgroundAudioHack()\n}\n\nVideoStreamMerger.prototype.getAudioContext = function () {\n  var self = this\n  return self._audioCtx\n}\n\nVideoStreamMerger.prototype.getAudioDestination = function () {\n  var self = this\n  return self._audioDestination\n}\n\nVideoStreamMerger.prototype.getCanvasContext = function () {\n  var self = this\n  return self._ctx\n}\n\nVideoStreamMerger.prototype._backgroundAudioHack = function () {\n  var self = this\n\n  // stop browser from throttling timers by playing almost-silent audio\n  var source = self._audioCtx.createConstantSource()\n  var gainNode = self._audioCtx.createGain()\n  gainNode.gain.value = 0.001 // required to prevent popping on start\n  source.connect(gainNode)\n  gainNode.connect(self._audioCtx.destination)\n  source.start()\n}\n\nVideoStreamMerger.prototype._setupConstantNode = function () {\n  var self = this\n\n  var constantAudioNode = self._audioCtx.createConstantSource()\n  constantAudioNode.start()\n\n  var gain = self._audioCtx.createGain() // gain node prevents quality drop\n  gain.gain.value = 0\n\n  constantAudioNode.connect(gain)\n  gain.connect(self._audioDestination)\n}\n\nVideoStreamMerger.prototype.updateIndex = function (mediaStream, index) {\n  var self = this\n\n  if (typeof mediaStream === 'string') {\n    mediaStream = {\n      id: mediaStream\n    }\n  }\n\n  index = index == null ? self._streams.length : index\n\n  for (var i = 0; i < self._streams.length; i++) {\n    if (mediaStream.id === self._streams[i].id) {\n      var stream = self._streams.splice(i, 1)[0]\n      stream.index = index\n      self._streams.splice(stream.index, 0, stream)\n    }\n  }\n}\n\n// convenience function for adding a media element\nVideoStreamMerger.prototype.addMediaElement = function (id, element, opts) {\n  var self = this\n\n  opts = opts || {}\n\n  opts.x = opts.x || 0\n  opts.y = opts.y || 0\n  opts.width = opts.width || self.width\n  opts.height = opts.height || self.height\n  opts.mute = opts.mute || opts.muted || false\n\n  opts.oldDraw = opts.draw\n  opts.oldAudioEffect = opts.audioEffect\n\n  if (element.tagName === 'VIDEO') {\n    opts.draw = function (ctx, _, done) {\n      if (opts.oldDraw) {\n        opts.oldDraw(ctx, element, done)\n      } else {\n        ctx.drawImage(element, opts.x, opts.y, opts.width, opts.height)\n        done()\n      }\n    }\n  } else {\n    opts.draw = null\n  }\n\n  if (!opts.mute) {\n    var audioSource = element._mediaElementSource || self.getAudioContext().createMediaElementSource(element)\n    element._mediaElementSource = audioSource // can only make one source per element, so store it for later (ties the source to the element's garbage collection)\n    audioSource.connect(self.getAudioContext().destination) // play audio from original element\n\n    var gainNode = self.getAudioContext().createGain()\n    audioSource.connect(gainNode)\n    if (element.muted) {\n      // keep the element \"muted\" while having audio on the merger\n      element.muted = false\n      element.volume = 0.001\n      gainNode.gain.value = 1000\n    } else {\n      gainNode.gain.value = 1\n    }\n    opts.audioEffect = function (_, destination) {\n      if (opts.oldAudioEffect) {\n        opts.oldAudioEffect(gainNode, destination)\n      } else {\n        gainNode.connect(destination)\n      }\n    }\n    opts.oldAudioEffect = null\n  }\n\n  self.addStream(id, opts)\n}\n\nVideoStreamMerger.prototype.addStream = function (mediaStream, opts) {\n  var self = this\n\n  if (typeof mediaStream === 'string') {\n    return self._addData(mediaStream, opts)\n  }\n\n  opts = opts || {}\n  var stream = {}\n\n  stream.isData = false\n  stream.x = opts.x || 0\n  stream.y = opts.y || 0\n  stream.width = opts.width || self.width\n  stream.height = opts.height || self.height\n  stream.draw = opts.draw || null\n  stream.mute = opts.mute || opts.muted || false\n  stream.audioEffect = opts.audioEffect || null\n  stream.index = opts.index == null ? self._streams.length : opts.index\n\n  // If it is the same MediaStream, we can reuse our video element (and ignore sound)\n  var videoElement = null\n  for (var i = 0; i < self._streams.length; i++) {\n    if (self._streams[i].id === mediaStream.id) {\n      videoElement = self._streams[i].element\n    }\n  }\n\n  if (!videoElement) {\n    videoElement = document.createElement('video')\n    videoElement.autoplay = true\n    videoElement.muted = true\n    videoElement.srcObject = mediaStream\n    videoElement.setAttribute('style', 'position:fixed; left: 0px; top:0px; pointer-events: none; opacity:0')\n    document.body.appendChild(videoElement)\n\n    if (!stream.mute) {\n      stream.audioSource = self._audioCtx.createMediaStreamSource(mediaStream)\n      stream.audioOutput = self._audioCtx.createGain() // Intermediate gain node\n      stream.audioOutput.gain.value = 1\n      if (stream.audioEffect) {\n        stream.audioEffect(stream.audioSource, stream.audioOutput)\n      } else {\n        stream.audioSource.connect(stream.audioOutput) // Default is direct connect\n      }\n      stream.audioOutput.connect(self._audioDestination)\n    }\n  }\n\n  stream.element = videoElement\n  stream.id = mediaStream.id || null\n  self._streams.splice(stream.index, 0, stream)\n}\n\nVideoStreamMerger.prototype.removeStream = function (mediaStream) {\n  var self = this\n\n  if (typeof mediaStream === 'string') {\n    mediaStream = {\n      id: mediaStream\n    }\n  }\n\n  for (var i = 0; i < self._streams.length; i++) {\n    if (mediaStream.id === self._streams[i].id) {\n      if (self._streams[i].audioSource) {\n        self._streams[i].audioSource = null\n      }\n      if (self._streams[i].audioOutput) {\n        self._streams[i].audioOutput.disconnect(self._audioDestination)\n        self._streams[i].audioOutput = null\n      }\n\n      self._streams[i] = null\n      self._streams.splice(i, 1)\n      i--\n    }\n  }\n}\n\nVideoStreamMerger.prototype._addData = function (key, opts) {\n  var self = this\n\n  opts = opts || {}\n  var stream = {}\n\n  stream.isData = true\n  stream.draw = opts.draw || null\n  stream.audioEffect = opts.audioEffect || null\n  stream.id = key\n  stream.element = null\n  stream.index = opts.index == null ? self._streams.length : opts.index\n\n  if (stream.audioEffect) {\n    stream.audioOutput = self._audioCtx.createGain() // Intermediate gain node\n    stream.audioOutput.gain.value = 1\n    stream.audioEffect(null, stream.audioOutput)\n    stream.audioOutput.connect(self._audioDestination)\n  }\n\n  self._streams.splice(stream.index, 0, stream)\n}\n\nVideoStreamMerger.prototype.start = function () {\n  var self = this\n\n  self.started = true\n  window.requestAnimationFrame(self._draw.bind(self))\n  // setInterval(() =>{ self._draw.bind(self)()}, 50)\n  // Add video\n  self.result = self._canvas.captureStream(self.fps)\n\n  // Remove \"dead\" audio track\n  var deadTrack = self.result.getAudioTracks()[0]\n  if (deadTrack) self.result.removeTrack(deadTrack)\n\n  // Add audio\n  var audioTracks = self._audioDestination.stream.getAudioTracks()\n  self.result.addTrack(audioTracks[0])\n}\n\nVideoStreamMerger.prototype._draw = function () {\n  var self = this\n  if (!self.started) return\n\n  var awaiting = self._streams.length\n  function done () {\n    awaiting--\n    if (awaiting <= 0) window.requestAnimationFrame(self._draw.bind(self))\n  }\n\n  if (self.clearRect) {\n    self._ctx.clearRect(0, 0, self.width, self.height)\n  }\n  self._streams.forEach(function (video) {\n    if (video.draw) { // custom frame transform\n      video.draw(self._ctx, video.element, done)\n    } else if (!video.isData) {\n      self._ctx.drawImage(video.element, video.x, video.y, video.width, video.height)\n      done()\n    } else {\n      done()\n    }\n  })\n\n  if (self._streams.length === 0) done()\n}\n\nVideoStreamMerger.prototype.destroy = function () {\n  var self = this\n\n  self.started = false\n\n  self._canvas = null\n  self._ctx = null\n  self._streams = []\n  self._audioCtx.close()\n  self._audioCtx = null\n  self._audioDestination = null\n\n  self.result.getTracks().forEach(function (t) {\n    t.stop()\n  })\n  self.result = null\n}\n\nmodule.exports = VideoStreamMerger\n","module.exports = clamp\n\nfunction clamp(value, min, max) {\n  return min < max\n    ? (value < min ? min : value > max ? max : value)\n    : (value < max ? max : value > min ? min : value)\n}\n","var clamp = require('clamp')\n\nmodule.exports = frequencyToIndex\nfunction frequencyToIndex (frequency, sampleRate, frequencyBinCount) {\n  var nyquist = sampleRate / 2\n  var index = Math.round(frequency / nyquist * frequencyBinCount)\n  return clamp(index, 0, frequencyBinCount)\n}\n","var frequencyToIndex = require('audio-frequency-to-index')\n\nmodule.exports = analyserFrequencyAverage.bind(null, 255)\nmodule.exports.floatData = analyserFrequencyAverage.bind(null, 1)\n\nfunction analyserFrequencyAverage (div, analyser, frequencies, minHz, maxHz) {\n  var sampleRate = analyser.context.sampleRate\n  var binCount = analyser.frequencyBinCount\n  var start = frequencyToIndex(minHz, sampleRate, binCount)\n  var end = frequencyToIndex(maxHz, sampleRate, binCount)\n  var count = end - start\n  var sum = 0\n  for (; start < end; start++) {\n    sum += frequencies[start] / div\n  }\n  return count === 0 ? 0 : (sum / count)\n}\n","'use strict';\nvar analyserFrequency = require('analyser-frequency-average');\n\nmodule.exports = function(audioContext, stream, opts) {\n\n  opts = opts || {};\n\n  var defaults = {\n    fftSize: 1024,\n    bufferLen: 1024,\n    smoothingTimeConstant: 0.2,\n    minCaptureFreq: 85,         // in Hz\n    maxCaptureFreq: 255,        // in Hz\n    noiseCaptureDuration: 1000, // in ms\n    minNoiseLevel: 0.3,         // from 0 to 1\n    maxNoiseLevel: 0.7,         // from 0 to 1\n    avgNoiseMultiplier: 1.2,\n    onVoiceStart: function() {\n    },\n    onVoiceStop: function() {\n    },\n    onUpdate: function(val) {\n    }\n  };\n\n  var options = {};\n  for (var key in defaults) {\n    options[key] = opts.hasOwnProperty(key) ? opts[key] : defaults[key];\n  }\n\n  var baseLevel = 0;\n  var voiceScale = 1;\n  var activityCounter = 0;\n  var activityCounterMin = 0;\n  var activityCounterMax = 60;\n  var activityCounterThresh = 5;\n\n  var envFreqRange = [];\n  var isNoiseCapturing = true;\n  var prevVadState = undefined;\n  var vadState = false;\n  var captureTimeout = null;\n\n  var source = audioContext.createMediaStreamSource(stream);\n  var analyser = audioContext.createAnalyser();\n  analyser.smoothingTimeConstant = options.smoothingTimeConstant;\n  analyser.fftSize = options.fftSize;\n\n  var scriptProcessorNode = audioContext.createScriptProcessor(options.bufferLen, 1, 1);\n  connect();\n  scriptProcessorNode.onaudioprocess = monitor;\n\n  if (isNoiseCapturing) {\n    //console.log('VAD: start noise capturing');\n    captureTimeout = setTimeout(init, options.noiseCaptureDuration);\n  }\n\n  function init() {\n    //console.log('VAD: stop noise capturing');\n    isNoiseCapturing = false;\n\n    envFreqRange = envFreqRange.filter(function(val) {\n      return val;\n    }).sort();\n    var averageEnvFreq = envFreqRange.length ? envFreqRange.reduce(function (p, c) { return Math.min(p, c) }, 1) : (options.minNoiseLevel || 0.1);\n\n    baseLevel = averageEnvFreq * options.avgNoiseMultiplier;\n    if (options.minNoiseLevel && baseLevel < options.minNoiseLevel) baseLevel = options.minNoiseLevel;\n    if (options.maxNoiseLevel && baseLevel > options.maxNoiseLevel) baseLevel = options.maxNoiseLevel;\n\n    voiceScale = 1 - baseLevel;\n\n    //console.log('VAD: base level:', baseLevel);\n  }\n\n  function connect() {\n    source.connect(analyser);\n    analyser.connect(scriptProcessorNode);\n    scriptProcessorNode.connect(audioContext.destination);\n  }\n\n  function disconnect() {\n    scriptProcessorNode.disconnect();\n    analyser.disconnect();\n    source.disconnect();\n  }\n\n  function destroy() {\n    captureTimeout && clearTimeout(captureTimeout);\n    disconnect();\n    scriptProcessorNode.onaudioprocess = null;\n  }\n\n  function monitor() {\n    var frequencies = new Uint8Array(analyser.frequencyBinCount);\n    analyser.getByteFrequencyData(frequencies);\n\n    var average = analyserFrequency(analyser, frequencies, options.minCaptureFreq, options.maxCaptureFreq);\n    if (isNoiseCapturing) {\n      envFreqRange.push(average);\n      return;\n    }\n\n    if (average >= baseLevel && activityCounter < activityCounterMax) {\n      activityCounter++;\n    } else if (average < baseLevel && activityCounter > activityCounterMin) {\n      activityCounter--;\n    }\n    vadState = activityCounter > activityCounterThresh;\n\n    if (prevVadState !== vadState) {\n      vadState ? onVoiceStart() : onVoiceStop();\n      prevVadState = vadState;\n    }\n\n    options.onUpdate(Math.max(0, average - baseLevel) / voiceScale);\n  }\n\n  function onVoiceStart() {\n    options.onVoiceStart();\n  }\n\n  function onVoiceStop() {\n    options.onVoiceStop();\n  }\n\n  return {connect: connect, disconnect: disconnect, destroy: destroy};\n};","'use strict';\nvar vad = require('../node_modules/voice-activity-detection/index.js');\nvar VideoStreamMerger = require('video-stream-merger')\n\nvar localStream;\nvar peer_con;\nvar remoteStream;\nvar peer;\nvar is_host = false;\nvar central_peer = false;\n\nvar merger = new VideoStreamMerger();;\nvar localVideo = document.querySelector('#localVideo');\nvar remoteVideo = document.querySelector('#remoteVideo');\n\nrequestMic();\n\nfunction requestMic() {\n  try {\n    window.AudioContext = window.AudioContext || window.webkitAudioContext;\n    audioContext = new AudioContext();\n\n    // navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;\n    // navigator.getUserMedia({audio: true}, startUserMedia, handleMicConnectError);\n  } catch (e) {\n    // handleUserMediaError();\n  }\n}\n/////////////////////////////////////////////\n\nvar room = 'foo';\nvar peer_connections =[];\n// var socket = io.connect(\"192.168.31.238:9090\");\nvar socket = io.connect(\"ec2-18-220-215-162.us-east-2.compute.amazonaws.com:9090\");\n\nvar audioContext;\nvar pcConfig = {\n  'iceServers': [\n    {'urls': 'stun:stun.l.google.com:19302'},\n    // {'urls': 'turn:numb.viagenie.ca'},\n    // {'urls': 'turn:d1.synergy.net:3478'}\n  ]\n};\n\nsocket.on('remove_host', function (){\n  console.log(\"host was removing\");\n  if (is_host){\n    console.log(\"peer_connections\", peer_connections.length);\n    // const con = peer_connections[0];\n    // con.close();\n    // peer_connections = []\n  }\n  is_host = false;\n});\n\nfunction remove_connection_for_main_peer(peer_connections){\n  for (let i in peer_connections) {\n    if (peer_connections[i].signalingState  == \"closed\"){\n      peer_connections.splice(i, 1);\n      remove_connection_for_main_peer(peer_connections)\n    }\n  }\n}\n\nfunction close_connection_for_main_peer(){\n  console.log(\"delete connection\");\n  if (!central_peer){\n    return;\n  }\n  for (let i in peer_connections) {\n    const con = peer_connections[i]\n    if (con.connection_type  == \"peer_to_host\"){\n      con.close()\n    }\n  }\n  remove_connection_for_main_peer(peer_connections)\n}\n\nsocket.on('peer_to_host', function (peer_id, my_id){\n  close_connection_for_main_peer();\n  console.log(\"my socket id\", my_id);\n  console.log(\"peer_to_host to\", peer_id);\n  peer = peer_id;\n  createPeerConnection('peer_to_host');\n});\n\nsocket.on('host_to_peer', function(peer_id) {\n  peer = peer_id;\n  console.log(\"host_to_peer to\", peer_id);\n  createPeerConnection(\"host_to_peer\");\n\n  if (!central_peer) {\n    if (!is_host){\n       peer_con.addStream(remoteStream);\n    }else{\n       peer_con.addStream(localStream);\n    }\n  } else {\n\n    merger.addStream(localStream, {});\n    merger.start();\n    console.log(\"merger stream added\");\n    peer_con.addStream(merger.result);\n    remoteVideo.srcObject = merger.result;\n  }\n  doCall()\n});\n\nsocket.on('first', function (){\n  is_host = true;\n  central_peer = true;\n});\n\n\n\n// socket.on('created', function(my_own_id) {\n//   console.log(my_own_id);\n//   is_host = true;\n//   createPeerConnection();\n//   pc.addStream(localStream);\n// });\n\nfunction sendMessage(message) {\n  socket.emit('message', peer, message);\n}\n\n// This client receives a message\nsocket.on('message', function(message) {\n  if (message.type === 'offer') {\n    peer_con.setRemoteDescription(new RTCSessionDescription(message));\n    doAnswer();\n  } else if (message.type === 'answer') {\n    peer_con.setRemoteDescription(new RTCSessionDescription(message));\n  } else if (message.type === 'candidate') {\n    var candidate = new RTCIceCandidate({\n      sdpMLineIndex: message.label,\n      candidate: message.candidate\n    });\n    peer_con.addIceCandidate(candidate);\n  } else if (message === 'bye') {\n    handleRemoteHangup();\n  }\n});\n\n////////////////////////////////////////////////////\n\nfunction doAnswer() {\n  console.log('Sending answer to peer.');\n  peer_con.createAnswer().then(\n    setLocalAndSendMessage,\n    onCreateSessionDescriptionError\n  );\n}\n\n/////////////////////////////////////////////////////////\n\nfunction createPeerConnection(connection_type) {\n  try {\n    const len = peer_connections.push(new RTCPeerConnection(null));\n    peer_con = peer_connections[len-1];\n    peer_con.connection_type = connection_type;\n    peer_con.setConfiguration(pcConfig);\n    peer_con.onicecandidate = handleIceCandidate;\n    peer_con.onaddstream = handleRemoteStreamAdded;\n    peer_con.onremovestream = handleRemoteStreamRemoved;\n  } catch (e) {\n    console.log(e);\n    return;\n  }\n}\n\nfunction handleIceCandidate(event) {\n  if (event.candidate) {\n    sendMessage({\n      type: 'candidate',\n      label: event.candidate.sdpMLineIndex,\n      id: event.candidate.sdpMid,\n      candidate: event.candidate.candidate\n    });\n  } else {\n  }\n}\n\nfunction handleCreateOfferError(event) {\n}\n\nfunction doCall() {\n  peer_con.createOffer(setLocalAndSendMessage, handleCreateOfferError);\n}\n\nfunction setLocalAndSendMessage(sessionDescription) {\n  peer_con.setLocalDescription(sessionDescription);\n  sendMessage(sessionDescription);\n}\n\nfunction handleRemoteStreamAdded(event) {\n  console.log(\"new remote stream\");\n\n  // setInterval(function () {\n  //    console.log(\"try run starts\");\n  //    peer_con.getStats(function(report){\n  //      report.result().forEach(function (result) {\n  //         var item = {};\n  //         result.names().forEach(function (name) {\n  //             item[name] = result.stat(name);\n  //         });\n  //         item.id = result.id;\n  //         item.type = result.type;\n  //         item.timestamp = result.timestamp;\n  //         console.log(item);\n  //     });\n  //    });\n  //   },5000);\n  if (central_peer){\n    if (remoteStream){\n      merger.removeStream(remoteStream);\n    }else {\n      merger.removeStream(localStream);\n    }\n    merger.addStream(event.stream);\n    remoteStream = event.stream;\n    // remoteVideo.srcObject = remoteStream;\n    return;\n  }else if (peer_connections.length > 2) {\n    remoteStream = event.stream;\n    remoteVideo.srcObject = remoteStream;\n    console.log(\"add to old connection\");\n    console.log(\" connection length\", peer_connections.length);\n    var con_before = peer_connections[peer_connections.length - 2];\n    con_before.addStream(remoteStream);\n  } else {\n    remoteStream = event.stream;\n    remoteVideo.srcObject = remoteStream;\n  }\n}\n//\nfunction handleRemoteStreamRemoved(event) {\n}\n\nfunction onCreateSessionDescriptionError(error) {\n}\n\nwindow.onbeforeunload = function() {\n  socket.emit('remove_peer', peer);\n};\n\n//////////////////////////////////////////////////\nfunction on_voice_start() {\n  console.log(\"voice started\", is_host);\n  if (is_host == false){\n    socket.emit('voice_start', central_peer);\n    if (central_peer){\n      merger.removeStream(merger._streams[0]);\n      merger.addStream(localStream);\n      // remoteStream = null;\n    }\n  }\n  is_host = true;\n  console.log(\"host\");\n}\n\nfunction add_voice_detection(stream) {\n  const options = {\n    fftSize: 1024,\n    bufferLen: 1024,\n    smoothingTimeConstant: 0.2,\n    minCaptureFreq: 85,         // in Hz\n    maxCaptureFreq: 255,        // in Hz\n    noiseCaptureDuration: 1000, // in ms\n    minNoiseLevel: 0.3,         // from 0 to 1\n    maxNoiseLevel: 0.7,         // from 0 to 1\n    avgNoiseMultiplier: 1.2,\n    onVoiceStart: on_voice_start,\n    // onVoiceStop: function() {console.log(\"stop\")},\n  };\n  vad(audioContext, stream, options);\n}\n\nfunction gotStream(stream) {\n  // window.AudioContext = window.AudioContext || window.webkitAudioContext;\n  // audioContext = new AudioContext();\n  localStream = stream;\n  // add_voice_detection(localStream);\n  localVideo.srcObject = stream;\n  localStream.getAudioTracks()[0].enabled = false;\n  socket.emit('create or join', room);\n}\n\nnavigator.mediaDevices.getUserMedia({\n    audio: true,\n    video: true\n  })\n  .then(gotStream)\n  .catch(function(e) {\n    alert('getUserMedia() error: ' + e);\n  });\n//////////////////////////////////////////////////\nconst mute_button = document.querySelector('#mute_button');\nlet vad_was_enabled = false;\nmute_button.addEventListener(\"click\", function(e){\n  const audio = localStream.getAudioTracks()[0];\n  audio.enabled = !(audio.enabled);\n  if (audio.enabled){\n    e.target.innerText = \"MUTE\";\n  }else{\n    e.target.innerText = \"UNMUTE\";\n  }\n  if (!vad_was_enabled) {\n    create_audio();\n    vad_was_enabled = true;\n  }\n});\n function create_audio(){\n  // window.AudioContext = window.AudioContext || window.webkitAudioContext;\n  // audioContext = new AudioContext();\n  add_voice_detection(localStream);\n};\n\nconst remove_button = document.querySelector('#remove_button');\n remove_button.addEventListener(\"click\", function(e){\n   peer_connections[peer_connections.length-1].close();\n })\n// var network = new ActiveXObject('WScript.Network');\n// console.log(network.UserName);"],"sourceRoot":""}