{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///./node_modules/video-stream-merger/src/index.js","webpack:///./node_modules/clamp/index.js","webpack:///./node_modules/audio-frequency-to-index/index.js","webpack:///./node_modules/analyser-frequency-average/index.js","webpack:///./node_modules/voice-activity-detection/index.js","webpack:///./src/main.js"],"names":[],"mappings":";AAAA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA,yDAAiD,cAAc;AAC/D;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;;AAGA;AACA;;;;;;;ACnEA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,qDAAqD,YAAY;AACjE;;AAEA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,iBAAiB,0BAA0B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,0BAA0B;AAC3C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,uDAAuD,WAAW,SAAS,sBAAsB;AACjG;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,iBAAiB,0BAA0B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,oBAAoB,yBAAyB;AAC7C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;;AAEA;;;;;;;ACnUA;;AAEA;AACA;AACA;AACA;AACA;;;;;;;ACNA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACPA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,aAAa;AACrB;AACA;AACA;AACA;;;;;;;;AChBA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL,oFAAoF,wBAAwB;;AAE5G;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,UAAU;AACV,E;;;;;;;AC/HA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,+BAA+B,YAAY;AAC3C,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK,uCAAuC;AAC5C,QAAQ,gCAAgC;AACxC,QAAQ;AACR;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,oCAAoC;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;;AAGD;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA,eAAe,gBAAgB;AAC/B,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA,uCAAuC;AACvC;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,CAAC;;AAED;AACA,sCAAsC;AACtC,mDAAmD;AACnD;AACA;AACA;AACA;AACA;AACA,eAAe,OAAO;AACtB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA,UAAU;AACV,SAAS;AACT,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB,mDAAmD;;AAE3F;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,0BAA0B,QAAQ,yBAAyB;AAC3D,QAAQ;AACR;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,QAAQ,yBAAyB;AACxD,KAAK;AACL;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,EAAE","file":"index.bundle.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 5);\n","/* globals window */\n\nmodule.exports = VideoStreamMerger\n\nfunction VideoStreamMerger (opts) {\n  var self = this\n  if (!(self instanceof VideoStreamMerger)) return new VideoStreamMerger(opts)\n\n  opts = opts || {}\n\n  var AudioContext = window.AudioContext || window.webkitAudioContext\n  var audioSupport = !!(AudioContext && (self._audioCtx = (opts.audioContext || new AudioContext())).createMediaStreamDestination)\n  var canvasSupport = !!document.createElement('canvas').captureStream\n  var supported = audioSupport && canvasSupport\n  if (!supported) {\n    throw new Error('Unsupported browser')\n  }\n  self.width = opts.width || 400\n  self.height = opts.height || 300\n  self.fps = opts.fps || 25\n  self.clearRect = opts.clearRect === undefined ? true : opts.clearRect\n\n  // Hidden canvas element for merging\n  self._canvas = document.createElement('canvas')\n  self._canvas.setAttribute('width', self.width)\n  self._canvas.setAttribute('height', self.height)\n  self._canvas.setAttribute('style', 'position:fixed; left: 110%; pointer-events: none') // Push off screen\n  self._ctx = self._canvas.getContext('2d')\n\n  self._streams = []\n\n  self._audioDestination = self._audioCtx.createMediaStreamDestination()\n\n  self._setupConstantNode() // HACK for wowza #7, #10\n\n  self.started = false\n  self.result = null\n\n  self._backgroundAudioHack()\n}\n\nVideoStreamMerger.prototype.getAudioContext = function () {\n  var self = this\n  return self._audioCtx\n}\n\nVideoStreamMerger.prototype.getAudioDestination = function () {\n  var self = this\n  return self._audioDestination\n}\n\nVideoStreamMerger.prototype.getCanvasContext = function () {\n  var self = this\n  return self._ctx\n}\n\nVideoStreamMerger.prototype._backgroundAudioHack = function () {\n  var self = this\n\n  // stop browser from throttling timers by playing almost-silent audio\n  var source = self._audioCtx.createConstantSource()\n  var gainNode = self._audioCtx.createGain()\n  gainNode.gain.value = 0.001 // required to prevent popping on start\n  source.connect(gainNode)\n  gainNode.connect(self._audioCtx.destination)\n  source.start()\n}\n\nVideoStreamMerger.prototype._setupConstantNode = function () {\n  var self = this\n\n  var constantAudioNode = self._audioCtx.createConstantSource()\n  constantAudioNode.start()\n\n  var gain = self._audioCtx.createGain() // gain node prevents quality drop\n  gain.gain.value = 0\n\n  constantAudioNode.connect(gain)\n  gain.connect(self._audioDestination)\n}\n\nVideoStreamMerger.prototype.updateIndex = function (mediaStream, index) {\n  var self = this\n\n  if (typeof mediaStream === 'string') {\n    mediaStream = {\n      id: mediaStream\n    }\n  }\n\n  index = index == null ? self._streams.length : index\n\n  for (var i = 0; i < self._streams.length; i++) {\n    if (mediaStream.id === self._streams[i].id) {\n      var stream = self._streams.splice(i, 1)[0]\n      stream.index = index\n      self._streams.splice(stream.index, 0, stream)\n    }\n  }\n}\n\n// convenience function for adding a media element\nVideoStreamMerger.prototype.addMediaElement = function (id, element, opts) {\n  var self = this\n\n  opts = opts || {}\n\n  opts.x = opts.x || 0\n  opts.y = opts.y || 0\n  opts.width = opts.width || self.width\n  opts.height = opts.height || self.height\n  opts.mute = opts.mute || opts.muted || false\n\n  opts.oldDraw = opts.draw\n  opts.oldAudioEffect = opts.audioEffect\n\n  if (element.tagName === 'VIDEO') {\n    opts.draw = function (ctx, _, done) {\n      if (opts.oldDraw) {\n        opts.oldDraw(ctx, element, done)\n      } else {\n        ctx.drawImage(element, opts.x, opts.y, opts.width, opts.height)\n        done()\n      }\n    }\n  } else {\n    opts.draw = null\n  }\n\n  if (!opts.mute) {\n    var audioSource = element._mediaElementSource || self.getAudioContext().createMediaElementSource(element)\n    element._mediaElementSource = audioSource // can only make one source per element, so store it for later (ties the source to the element's garbage collection)\n    audioSource.connect(self.getAudioContext().destination) // play audio from original element\n\n    var gainNode = self.getAudioContext().createGain()\n    audioSource.connect(gainNode)\n    if (element.muted) {\n      // keep the element \"muted\" while having audio on the merger\n      element.muted = false\n      element.volume = 0.001\n      gainNode.gain.value = 1000\n    } else {\n      gainNode.gain.value = 1\n    }\n    opts.audioEffect = function (_, destination) {\n      if (opts.oldAudioEffect) {\n        opts.oldAudioEffect(gainNode, destination)\n      } else {\n        gainNode.connect(destination)\n      }\n    }\n    opts.oldAudioEffect = null\n  }\n\n  self.addStream(id, opts)\n}\n\nVideoStreamMerger.prototype.addStream = function (mediaStream, opts) {\n  var self = this\n\n  if (typeof mediaStream === 'string') {\n    return self._addData(mediaStream, opts)\n  }\n\n  opts = opts || {}\n  var stream = {}\n\n  stream.isData = false\n  stream.x = opts.x || 0\n  stream.y = opts.y || 0\n  stream.width = opts.width || self.width\n  stream.height = opts.height || self.height\n  stream.draw = opts.draw || null\n  stream.mute = opts.mute || opts.muted || false\n  stream.audioEffect = opts.audioEffect || null\n  stream.index = opts.index == null ? self._streams.length : opts.index\n\n  // If it is the same MediaStream, we can reuse our video element (and ignore sound)\n  var videoElement = null\n  for (var i = 0; i < self._streams.length; i++) {\n    if (self._streams[i].id === mediaStream.id) {\n      videoElement = self._streams[i].element\n    }\n  }\n\n  if (!videoElement) {\n    videoElement = document.createElement('video')\n    videoElement.autoplay = true\n    videoElement.muted = true\n    videoElement.srcObject = mediaStream\n    videoElement.setAttribute('style', 'position:fixed; left: 0px; top:0px; pointer-events: none; opacity:0')\n    document.body.appendChild(videoElement)\n\n    if (!stream.mute) {\n      stream.audioSource = self._audioCtx.createMediaStreamSource(mediaStream)\n      stream.audioOutput = self._audioCtx.createGain() // Intermediate gain node\n      stream.audioOutput.gain.value = 1\n      if (stream.audioEffect) {\n        stream.audioEffect(stream.audioSource, stream.audioOutput)\n      } else {\n        stream.audioSource.connect(stream.audioOutput) // Default is direct connect\n      }\n      stream.audioOutput.connect(self._audioDestination)\n    }\n  }\n\n  stream.element = videoElement\n  stream.id = mediaStream.id || null\n  self._streams.splice(stream.index, 0, stream)\n}\n\nVideoStreamMerger.prototype.removeStream = function (mediaStream) {\n  var self = this\n\n  if (typeof mediaStream === 'string') {\n    mediaStream = {\n      id: mediaStream\n    }\n  }\n\n  for (var i = 0; i < self._streams.length; i++) {\n    if (mediaStream.id === self._streams[i].id) {\n      if (self._streams[i].audioSource) {\n        self._streams[i].audioSource = null\n      }\n      if (self._streams[i].audioOutput) {\n        self._streams[i].audioOutput.disconnect(self._audioDestination)\n        self._streams[i].audioOutput = null\n      }\n\n      self._streams[i] = null\n      self._streams.splice(i, 1)\n      i--\n    }\n  }\n}\n\nVideoStreamMerger.prototype._addData = function (key, opts) {\n  var self = this\n\n  opts = opts || {}\n  var stream = {}\n\n  stream.isData = true\n  stream.draw = opts.draw || null\n  stream.audioEffect = opts.audioEffect || null\n  stream.id = key\n  stream.element = null\n  stream.index = opts.index == null ? self._streams.length : opts.index\n\n  if (stream.audioEffect) {\n    stream.audioOutput = self._audioCtx.createGain() // Intermediate gain node\n    stream.audioOutput.gain.value = 1\n    stream.audioEffect(null, stream.audioOutput)\n    stream.audioOutput.connect(self._audioDestination)\n  }\n\n  self._streams.splice(stream.index, 0, stream)\n}\n\nVideoStreamMerger.prototype.start = function () {\n  var self = this\n\n  self.started = true\n  window.requestAnimationFrame(self._draw.bind(self))\n  setInterval(() =>{ self._draw.bind(self)()}, 200)\n  // Add video\n  self.result = self._canvas.captureStream(self.fps)\n\n  // Remove \"dead\" audio track\n  var deadTrack = self.result.getAudioTracks()[0]\n  if (deadTrack) self.result.removeTrack(deadTrack)\n\n  // Add audio\n  var audioTracks = self._audioDestination.stream.getAudioTracks()\n  self.result.addTrack(audioTracks[0])\n}\n\nVideoStreamMerger.prototype._draw = function () {\n  var self = this\n  if (!self.started) return\n\n  var awaiting = self._streams.length\n  function done () {\n    awaiting--\n    // if (awaiting <= 0) window.requestAnimationFrame(self._draw.bind(self))\n  }\n\n  if (self.clearRect) {\n    self._ctx.clearRect(0, 0, self.width, self.height)\n  }\n  self._streams.forEach(function (video) {\n    if (video.draw) { // custom frame transform\n      video.draw(self._ctx, video.element, done)\n    } else if (!video.isData) {\n      self._ctx.drawImage(video.element, video.x, video.y, video.width, video.height)\n      done()\n    } else {\n      done()\n    }\n  })\n\n  if (self._streams.length === 0) done()\n}\n\nVideoStreamMerger.prototype.destroy = function () {\n  var self = this\n\n  self.started = false\n\n  self._canvas = null\n  self._ctx = null\n  self._streams = []\n  self._audioCtx.close()\n  self._audioCtx = null\n  self._audioDestination = null\n\n  self.result.getTracks().forEach(function (t) {\n    t.stop()\n  })\n  self.result = null\n}\n\nmodule.exports = VideoStreamMerger\n","module.exports = clamp\n\nfunction clamp(value, min, max) {\n  return min < max\n    ? (value < min ? min : value > max ? max : value)\n    : (value < max ? max : value > min ? min : value)\n}\n","var clamp = require('clamp')\n\nmodule.exports = frequencyToIndex\nfunction frequencyToIndex (frequency, sampleRate, frequencyBinCount) {\n  var nyquist = sampleRate / 2\n  var index = Math.round(frequency / nyquist * frequencyBinCount)\n  return clamp(index, 0, frequencyBinCount)\n}\n","var frequencyToIndex = require('audio-frequency-to-index')\n\nmodule.exports = analyserFrequencyAverage.bind(null, 255)\nmodule.exports.floatData = analyserFrequencyAverage.bind(null, 1)\n\nfunction analyserFrequencyAverage (div, analyser, frequencies, minHz, maxHz) {\n  var sampleRate = analyser.context.sampleRate\n  var binCount = analyser.frequencyBinCount\n  var start = frequencyToIndex(minHz, sampleRate, binCount)\n  var end = frequencyToIndex(maxHz, sampleRate, binCount)\n  var count = end - start\n  var sum = 0\n  for (; start < end; start++) {\n    sum += frequencies[start] / div\n  }\n  return count === 0 ? 0 : (sum / count)\n}\n","'use strict';\nvar analyserFrequency = require('analyser-frequency-average');\n\nmodule.exports = function(audioContext, stream, opts) {\n\n  opts = opts || {};\n\n  var defaults = {\n    fftSize: 1024,\n    bufferLen: 1024,\n    smoothingTimeConstant: 0.2,\n    minCaptureFreq: 85,         // in Hz\n    maxCaptureFreq: 255,        // in Hz\n    noiseCaptureDuration: 1000, // in ms\n    minNoiseLevel: 0.3,         // from 0 to 1\n    maxNoiseLevel: 0.7,         // from 0 to 1\n    avgNoiseMultiplier: 1.2,\n    onVoiceStart: function() {\n    },\n    onVoiceStop: function() {\n    },\n    onUpdate: function(val) {\n    }\n  };\n\n  var options = {};\n  for (var key in defaults) {\n    options[key] = opts.hasOwnProperty(key) ? opts[key] : defaults[key];\n  }\n\n  var baseLevel = 0;\n  var voiceScale = 1;\n  var activityCounter = 0;\n  var activityCounterMin = 0;\n  var activityCounterMax = 60;\n  var activityCounterThresh = 5;\n\n  var envFreqRange = [];\n  var isNoiseCapturing = true;\n  var prevVadState = undefined;\n  var vadState = false;\n  var captureTimeout = null;\n\n  var source = audioContext.createMediaStreamSource(stream);\n  var analyser = audioContext.createAnalyser();\n  analyser.smoothingTimeConstant = options.smoothingTimeConstant;\n  analyser.fftSize = options.fftSize;\n\n  var scriptProcessorNode = audioContext.createScriptProcessor(options.bufferLen, 1, 1);\n  connect();\n  scriptProcessorNode.onaudioprocess = monitor;\n\n  if (isNoiseCapturing) {\n    //console.log('VAD: start noise capturing');\n    captureTimeout = setTimeout(init, options.noiseCaptureDuration);\n  }\n\n  function init() {\n    //console.log('VAD: stop noise capturing');\n    isNoiseCapturing = false;\n\n    envFreqRange = envFreqRange.filter(function(val) {\n      return val;\n    }).sort();\n    var averageEnvFreq = envFreqRange.length ? envFreqRange.reduce(function (p, c) { return Math.min(p, c) }, 1) : (options.minNoiseLevel || 0.1);\n\n    baseLevel = averageEnvFreq * options.avgNoiseMultiplier;\n    if (options.minNoiseLevel && baseLevel < options.minNoiseLevel) baseLevel = options.minNoiseLevel;\n    if (options.maxNoiseLevel && baseLevel > options.maxNoiseLevel) baseLevel = options.maxNoiseLevel;\n\n    voiceScale = 1 - baseLevel;\n\n    //console.log('VAD: base level:', baseLevel);\n  }\n\n  function connect() {\n    source.connect(analyser);\n    analyser.connect(scriptProcessorNode);\n    scriptProcessorNode.connect(audioContext.destination);\n  }\n\n  function disconnect() {\n    scriptProcessorNode.disconnect();\n    analyser.disconnect();\n    source.disconnect();\n  }\n\n  function destroy() {\n    captureTimeout && clearTimeout(captureTimeout);\n    disconnect();\n    scriptProcessorNode.onaudioprocess = null;\n  }\n\n  function monitor() {\n    var frequencies = new Uint8Array(analyser.frequencyBinCount);\n    analyser.getByteFrequencyData(frequencies);\n\n    var average = analyserFrequency(analyser, frequencies, options.minCaptureFreq, options.maxCaptureFreq);\n    if (isNoiseCapturing) {\n      envFreqRange.push(average);\n      return;\n    }\n\n    if (average >= baseLevel && activityCounter < activityCounterMax) {\n      activityCounter++;\n    } else if (average < baseLevel && activityCounter > activityCounterMin) {\n      activityCounter--;\n    }\n    vadState = activityCounter > activityCounterThresh;\n\n    if (prevVadState !== vadState) {\n      vadState ? onVoiceStart() : onVoiceStop();\n      prevVadState = vadState;\n    }\n\n    options.onUpdate(Math.max(0, average - baseLevel) / voiceScale);\n  }\n\n  function onVoiceStart() {\n    options.onVoiceStart();\n  }\n\n  function onVoiceStop() {\n    options.onVoiceStop();\n  }\n\n  return {connect: connect, disconnect: disconnect, destroy: destroy};\n};","'use strict';\nvar vad = require('../node_modules/voice-activity-detection/index.js');\nvar VideoStreamMerger = require('video-stream-merger')\n\nvar localStream;\nvar peer_con;\nvar remoteStream;\nvar peer;\nlet conn_to_central;\nvar is_host = false;\nvar central_peer = false;\nlet current_sock_id = '';\nlet last_activity;\n\nconst sound_track_slots = [];\nvar merger = new VideoStreamMerger();\nvar localVideo = document.querySelector('#localVideo');\nvar remoteVideo = document.querySelector('#remoteVideo');\nvar tempVideo = document.querySelector('#tempVideo');\nconst main_stream = new MediaStream();\nlet c_array_index = '';\nrequestMic();\n\nfunction requestMic() {\n  try {\n    // window.AudioContext = window.AudioContext || window.webkitAudioContext;\n    audioContext = new AudioContext();\n\n    // navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;\n    // navigator.getUserMedia({audio: true}, startUserMedia, handleMicConnectError);\n  } catch (e) {\n    // handleUserMediaError();\n  }\n}\n/////////////////////////////////////////////\n\nvar room = 'foo';\nvar peer_connections =[];\n// var socket = io.connect(\"192.168.31.238:9090\");\nvar socket = io.connect(\"ec2-18-220-215-162.us-east-2.compute.amazonaws.com:9090\");\n\nvar audioContext;\nvar pcConfig = {\n  'iceServers': [\n    {'urls': 'stun:stun.l.google.com:19302'},\n    // {'urls': 'turn:numb.viagenie.ca'},\n    // {'urls': 'turn:d1.synergy.net:3478'}\n  ]\n};\n\n\nfunction sendMessage(message) {\n  socket.emit('message', peer, message);\n}\n\n// This client receives a message\nsocket.on('message', function(message) {\n  if (message.type === 'offer') {\n    peer_con.setRemoteDescription(new RTCSessionDescription(message));\n    doAnswer();\n  } else if (message.type === 'answer') {\n    console.log(\"3 answer\")\n    peer_con.setRemoteDescription(new RTCSessionDescription(message));\n  } else if (message.type === 'candidate') {\n    var candidate = new RTCIceCandidate({\n      sdpMLineIndex: message.label,\n      candidate: message.candidate\n    });\n    peer_con.addIceCandidate(candidate);\n    console.log(\"4 candidate\")\n  } else if (message === 'bye') {\n    handleRemoteHangup();\n  }\n});\n\nfunction doAnswer() {\n  console.log('Sending answer to peer.');\n  peer_con.createAnswer().then(\n    setLocalAndSendMessage,\n    onCreateSessionDescriptionError\n  );\n}\n\n/////////////////////////////////////////////////////////\n\nfunction  createPeerConnection(connection_type) {\n  try {\n    const len = peer_connections.push(new RTCPeerConnection(null));\n    peer_con = peer_connections[len-1];\n    peer_con.connection_type = connection_type;\n    peer_con.setConfiguration(pcConfig);\n    peer_con.onicecandidate = handleIceCandidate;\n    peer_con.onaddstream = handleRemoteStreamAdded;\n    peer_con.onremovestream = handleRemoteStreamRemoved;\n  } catch (e) {\n    console.log(e);\n    return;\n  }\n}\n\nfunction handleIceCandidate(event) {\n  if (event.candidate) {\n    sendMessage({\n      type: 'candidate',\n      label: event.candidate.sdpMLineIndex,\n      id: event.candidate.sdpMid,\n      candidate: event.candidate.candidate\n    });\n  } else {\n  }\n}\n\nfunction handleCreateOfferError(event) {\n}\n\nfunction doCall() {\n  peer_con.createOffer(setLocalAndSendMessage, handleCreateOfferError);\n}\n\nfunction setLocalAndSendMessage(sessionDescription) {\n  peer_con.setLocalDescription(sessionDescription);\n  sendMessage(sessionDescription);\n}\n\n//\nfunction handleRemoteStreamRemoved(event) {\n}\n\nfunction onCreateSessionDescriptionError(error) {\n}\n////////////////////////////////////////////////////\nsocket.on('remove_stream', function (stream_id, soket_id){\n  for (let i in sound_track_slots){\n    const slot = sound_track_slots[i];\n    if (slot.connection && slot.connection.host_id == soket_id){\n      slot.state = \"closed\";\n      slot.gain.disconnect(slot.dest);\n      break;\n    }\n  }\n});\n\nsocket.on('close_video_to_central', function (){\n  for (let i in peer_connections) {\n    const con = peer_connections[i]\n    if (con.connection_type  == \"to_main_host_video\"){\n      console.log(\"c stream remove \");\n      con.close()\n    }\n  }\n  remove_connection_for_main_peer(peer_connections);\n});\n\nfunction remove_connection_for_main_peer(peer_connections){\n  for (let i in peer_connections) {\n    if (peer_connections[i].signalingState  == \"closed\"){\n      peer_connections.splice(i, 1);\n      remove_connection_for_main_peer(peer_connections)\n    }\n  }\n}\n\nfunction close_connection_for_main_peer(){\n  if (central_peer){\n    return;\n  }\n  for (let i in peer_connections) {\n    const con = peer_connections[i]\n    if (con.connection_type  == \"to_main_host_sound\"){\n      console.log(\"delete connection\");\n      con.close()\n    }\n  }\n  remove_connection_for_main_peer(peer_connections)\n}\n\nsocket.on('peer_to_host', function (peer_id, video_slot_pos, sock_id){\n  if (sock_id){\n    current_sock_id = sock_id;\n  }\n  close_connection_for_main_peer();\n  console.log(\" 1 peer_to_host to\", peer_id);\n  // if (central_peer){\n  //   c_sound_peer_ids.push(peer_id);\n  //   if (c_video_peer_ids.length < 5) {\n  //     c_video_peer_ids.push({\"peer_id\": peer_id, \"stream\": false});\n  //   }\n  // }\n  peer = peer_id;\n  createPeerConnection('peer_to_host');\n  console.log(\" 2 create connection , video pos\", video_slot_pos, \"host id\",  peer_id);\n  peer_con.host_id = peer_id;\n  peer_con.video_slot_pos = video_slot_pos;\n});\n\n\nsocket.on('mute_own_channel', function (array_index){\n  // c_array_index = array_index;\n  console.log(\"c_array_index\", array_index);\n  remoteStream.getAudioTracks()[array_index].enabled = false;\n});\n\nfunction create_audio_track_slots(stream_count) {\n  if (sound_track_slots.length == stream_count) {\n    return;\n  }\n  for (let i=0; i<stream_count; i++){\n    const  track = {source:'', state:'free'};\n    track.gain  = audioContext.createGain();\n    track.gain.gain.value = 1;\n    track.dest = audioContext.createMediaStreamDestination();\n    track.gain.connect(track.dest);\n    main_stream.addTrack(track.dest.stream.getAudioTracks()[0]);\n    sound_track_slots.push(track);\n  }\n}\n\nsocket.on('host_to_peer', function(peer_id, to_main, sound_only) {\n  peer = peer_id;\n  console.log(\"host_to_peer to\", peer_id);\n\n  if (to_main){\n    if (sound_only){\n        createPeerConnection(\"to_main_host_sound\");\n        console.log(\"add stream id \", localStream.id);\n        const newStream = new MediaStream();\n        newStream.addTrack(localStream.getAudioTracks()[0]);\n        peer_con.addStream(newStream);\n        conn_to_central = peer_connections[peer_connections.length - 1];\n    }else {\n        createPeerConnection(\"to_main_host_video\");\n        console.log(\"add stream id \", localStream.id);\n        const newStream = new MediaStream();\n        newStream.addTrack(localStream.getVideoTracks()[0]);\n        peer_con.addStream(newStream);\n    }\n  } else {\n\n    if (!central_peer) {\n      createPeerConnection(\"peer transmit to peers\");\n      merger.addStream(remoteStream, {});\n      merger.start();\n      peer_con.addStream(merger.result);\n    } else {\n      createPeerConnection(\"main transmit to peers\");\n      create_audio_track_slots(10);\n      main_stream.addTrack(merger.result.getVideoTracks()[0]);\n      remoteVideo.srcObject = main_stream;\n      remoteStream = main_stream;\n      peer_con.addStream(main_stream);\n    }\n  }\n  doCall()\n});\n\nsocket.on('first', function (sock_id){\n  current_sock_id = sock_id;\n  is_host = false;\n  central_peer = true;\n  merger.addStream(localStream, {\n          x:0,\n          y:0,\n          width: 200,\n          height:150,\n          mute: true // we don't want sound from the screen (if there is any)\n        });\n  merger.start();\n  console.log(\" local stream merger created\")\n});\n\nfunction add_sound_track(event, new_stream){\n  // tempVideo.srcObject = new_stream; // very important\n  const video_el = document.createElement(\"video\"); // todo destroy element somehow\n  video_el.srcObject = new_stream;\n  const source = audioContext.createMediaStreamSource(new_stream);\n  const gain = audioContext.createGain();\n  gain.gain.value = 1;\n  source.connect(gain);\n  for (let i=0; i<=10; i++){\n    const free_slot = sound_track_slots[i];\n    if (!free_slot.connection || free_slot.state == \"closed\"){\n      free_slot.gain = gain;\n      gain.connect(free_slot.dest);\n\n      free_slot.connection = event.target;\n      free_slot.state = \"connected\";\n      if (central_peer && !free_slot.connection.host_id){\n        free_slot.connection.host_id = current_sock_id;\n      }\n\n      if (current_sock_id != free_slot.connection.host_id){\n        socket.emit(\"mute_own_channel\", free_slot.connection.host_id, i);\n      }\n      break;\n    }\n  }\n}\n\nfunction handleRemoteStreamAdded(event) {\n  console.log(\"new remote stream\");\n\n  // setInterval(function () {\n  //    console.log(\"try run starts\");\n  //    peer_con.getStats(function(report){\n  //      report.result().forEach(function (result) {\n  //         var item = {};\n  //         result.names().forEach(function (name) {\n  //             item[name] = result.stat(name);\n  //         });\n  //         item.id = result.id;\n  //         item.type = result.type;\n  //         item.timestamp = result.timestamp;\n  //         console.log(item);\n  //     });\n  //    });\n  //   },5000);\n  if (central_peer){\n    const new_remote_stream = event.stream;\n    const video_track  = new_remote_stream.getVideoTracks().length;\n    console.log(\" 5 new stream video\", video_track);\n    if (video_track) {\n      const video_slot_pos = event.target.video_slot_pos;\n      merger.addStream(event.stream, {\n          x: (video_slot_pos == 0 || video_slot_pos == 3) ? 0 : 200, // position of the topleft corner\n          y: (video_slot_pos == 0 || video_slot_pos == 1) ? 0 : 150 ,\n          width: 200,\n          height: 150,\n          mute: true // we don't want sound from the screen (if there is any)\n        });\n\n    } else {\n      // merger.addStream(event.stream);\n      const new_stream = event.stream;\n      // console.log('new sound track appear', new Date(), new Date().getMilliseconds());\n      add_sound_track(event, new_stream);\n    }\n  } else if (peer_connections.length > 2) {\n    remoteStream = event.stream;\n    remoteVideo.srcObject = remoteStream;\n    var con_before = peer_connections[peer_connections.length - 2];\n    con_before.addStream(remoteStream);\n  } else {\n    remoteStream = event.stream;\n    remoteVideo.srcObject = remoteStream;\n  }\n}\n// setInterval(()=>{ if (!central_peer){console.log(remoteStream.getAudioTracks().length)}}, 3000);\n\nwindow.onbeforeunload = function() {\n  socket.emit('remove_peer', peer);\n};\n\n//////////////////////////////////////////////////\n// function on_voice_start() {\n//   if (is_host == false) {\n//     // console.log(\"c voice started\", new Date(), new Date().getMilliseconds());\n//     if (central_peer){\n//       add_sound_track({target:{host_id:current_sock_id}}, localStream);\n//     } else {\n//       socket.emit('voice_start', central_peer, true, true);\n//     }\n//     is_host = true;\n//   }\n// }\n\n// function on_voice_stop() {\n//   last_activity = new Date()\n// }\n//\n// setInterval(()=>{\n//   // console.log(new Date() - last_activity);\n//   if (conn_to_central && ((new Date() - last_activity) > 3000)){\n//     conn_to_central.close();\n//     is_host = false;\n//     conn_to_central = '';\n//     console.log(\"c stream removed\");\n//     peer_connections[peer_connections.length-1].close();\n//     peer_connections.splice(peer_connections.length-1, 1);\n//     socket.emit('remove_stream', localStream.id );\n//   }\n//   //for central\n//   if (central_peer && is_host && (new Date() - last_activity) > 3000) {\n//     is_host = false;\n//     console.log(\"m stream removed\");\n//     socket.emit('remove_stream', localStream.id );\n//   }\n//\n// }, 3000);\n\n// function add_voice_detection(stream) {\n//   const options = {\n//     fftSize: 1024,\n//     bufferLen: 1024,\n//     smoothingTimeConstant: 0.2,\n//     minCaptureFreq: 85,         // in Hz\n//     maxCaptureFreq: 255,        // in Hz\n//     noiseCaptureDuration: 1000, // in ms\n//     minNoiseLevel: 0.3,         // from 0 to 1\n//     maxNoiseLevel: 0.7,         // from 0 to 1\n//     avgNoiseMultiplier: 1.2,\n//     onVoiceStart: on_voice_start,\n//     onVoiceStop: on_voice_stop,\n//     onUpdate: function(val) {\n//       if (val > 0.1){\n//         last_activity = new Date()\n//       }\n//     }\n//   };\n//   vad(audioContext, stream, options);\n// }\n\nfunction gotStream(stream) {\n  // window.AudioContext = window.AudioContext || window.webkitAudioContext;\n  // audioContext = new AudioContext();\n  localStream = stream;\n  // add_voice_detection(localStream);\n  localVideo.srcObject = stream;\n  // localStream.getVideoTracks()[0].enabled = false;\n  localStream.getAudioTracks()[0].enabled = false;\n  socket.emit('create or join', room);\n  // if (!vad_was_enabled) {\n  //   create_audio();\n  //   vad_was_enabled = true;\n  // }\n}\n\nnavigator.mediaDevices.getUserMedia({\n    audio: true,\n    video: true\n  })\n  .then(gotStream)\n  .catch(function(e) {\n    alert('getUserMedia() error: ' + e);\n  });\n//////////////////////////////////////////////////\nconst mute_button = document.querySelector('#mute_button');\nlet vad_was_enabled = false;\nmute_button.addEventListener(\"click\", function(e){\n  // console.log(\"mute button pres\", new Date(), new Date().getMilliseconds());\n  const audio = localStream.getAudioTracks()[0];\n  audio.enabled = !(audio.enabled);\n  if (audio.enabled){\n    e.target.innerText = \"MUTE\";\n    if (central_peer){\n      add_sound_track({target:{host_id:current_sock_id}}, localStream);\n    } else {\n      socket.emit('voice_start', central_peer, true, true);\n    }\n  }else{\n    e.target.innerText = \"UNMUTE\";\n      // console.log(\"c voice started\", new Date(), new Date().getMilliseconds());\n    if (conn_to_central){\n      conn_to_central.close();\n      is_host = false;\n      conn_to_central = '';\n      // console.log(\"c stream removed\");\n      // for (let i in peer_connections){\n      //   const current_con  = peer_connections[i];\n      //\n      //   if (current_con.connection_type == \"to_main_host_sound\"){\n      //     current_con.close();\n      //     peer_connections.splice(i, 1);\n      //     break;\n      //   }\n      // }\n      socket.emit('remove_stream', localStream.id );\n    }\n    //for central\n    if (central_peer) {\n      console.log(\"m stream removed\");\n      socket.emit('remove_stream', localStream.id );\n    }\n  }\n\n});\n\n// function create_audio(){\n//   add_voice_detection(localStream);\n// };\n\nconst remove_button = document.querySelector('#remove_button');\n remove_button.addEventListener(\"click\", function(e){\n  peer_connections[peer_connections.length-1].close();\n  console.log(sound_track_slots)\n });\n\n"],"sourceRoot":""}